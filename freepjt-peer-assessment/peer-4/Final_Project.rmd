---
title: "Breast Cancer Prediction Project based out of the Breast Cancer Wisconsin (Diagnostic) Data Set"
subtitle: "HarvardX: PH125.9x Data Science - Choose your own project"
author: "Ashita Ranjan"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  pdf_document: 
    toc: true
    toc_depth: 3
    number_sections: true
geometry: margin=1in
biblio-style: apalike
documentclass: book
classoption: openany
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment=NA, message=FALSE, warning=FALSE)
```

# Overview

This is the final project of Capstone course offered in the Data Science program. 

An exploratory data analysis based out of the Breast Cancer Wisconsin (Diagnostic) Data Set is carried out in order to develop a machine learning algorithm that could predict whether a breast cancer cell is benign or malignant. The results will be explained. At the end, the report will end with some concluding remarks.


## Introduction

A neoplasm is a new and abnormal growth of tissue in some part of the body, especially as a characteristic of cancer. Neoplasms may be benign (not cancer) or malignant (cancer).

The human body is made up of billions of cells and cancer can start almost anywhere in the human body. As these tumors grow, some cancer cells can break off and travel to distant places in the body through the blood or the lymph system and form new tumors far from the original one. Unlike malignant tumors, benign tumors are those that stay in their primary location without invading other sites of the body. They do not spread to local structures or to distant parts of the body. Breast cancer refers to a pathology in which a tumor develops in the breast tissue.

Breast cancer is a type of cancer that starts in the breast. It can start in one or both breasts.Breast cancer occurs almost entirely in women, but men can get it too. In 2020, more than 2.3 million women were diagnosed with breast cancer worldwide and 685,000 died.

Mammography is the most common mass screening tool for an early detection of breast cancer because of its ability in detecting breast masses. After detection of suspicious breast masses, a biopsy test procedure would be carried out, such as Fine Needle Aspirates (FNA). This report focuses on that.Fine needle aspiration (FNA) is a type of biopsy that is performed with a small (21 to 25 gauge) needle to obtain samples of tissue and fluid from solid or cystic breast lesions. It is one of the many different modalities for diagnosing breast masses. It is then analysed under the microscope. Then, a small region of the breast mass cells is photographed in a grey scale image and further analysed using an image analysis program ‘Xcyt’. This program uses a curve-fitting to determine the edges of the nuclei from initial dots manually placed near these edges by a mouse.

The edges of the visible cell nuclei are manually placed with a mouse (red dots), ‘Xcyt’ program will then outline the nuclei (red circle). The interactive diagnosis process takes about 5 minutes per sample.

This project will make a performance comparison between different machine learning algorithms. This is needed in order to assess the correctness of classifying breast cancer data with respect to each algorithm in terms of accuracy, precision, sensitivity and specificity. This is needed in order to find the best diagnosis.

The major models used and tested will be supervised learning models (algorithms that use data), which are mostly used in these kinds of data analysis.

The utilization of data science and machine learning approaches in medical fields proves to be fruitful as such approaches may be considered of great assistance in the decision making process of medical practitioners. This can prove to be useful to the medical profession itself.


## Objective of the project

The objective of this report is to train machine learning models to predict whether a breast cancer cell is Benign or Malignant. Data will be transformed and its dimension reduced to reveal patterns in the dataset and create a more robust analysis.
As previously said, the optimal model will be selected following the resulting accuracy, sensitivity, and f1 score, amongst other factors. We will later define these metrics.
We can use machine learning method to extract the features of cancer cell nuclei image and classify them. It would be helpful to determine whether a given sample appears to be Benign ("B") or Malignant ("M").

The machine learning models that we will apply in this report try to create a classifier that provides a high accuracy level combined with a low rate of false-negatives (high sensitivity). 


## Dataset

The present report covers the Breast Cancer Wisconsin (Diagnostic) DataSet (https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/version/2) created by Dr. William H. Wolberg, physician at the University Of Wisconsin Hospital at Madison, Wisconsin, USA.
The data used for this project was collected in 1993 by the University of Wisconsin and it is composed by the biopsy result of 569 patients in Wisconsin Hospital.

• [Wisconsin Breast Cancer Diagnostic Dataset] https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/version/2

The .csv format file containing the data is loaded from my github account.

```{r, echo = FALSE, message = FALSE, warning = FALSE, eval = TRUE}

if(!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(corrplot)) install.packages("recorrplotadr", repos = "http://cran.us.r-project.org")
if(!require(gridExtra)) install.packages("gridExtra", repos = "http://cran.us.r-project.org")
if(!require(pROC)) install.packages("pROC", repos = "http://cran.us.r-project.org")
if(!require(caTools)) install.packages("caTools", repos = "http://cran.us.r-project.org")
if(!require(caretEnsemble)) install.packages("caretEnsemble", repos = "http://cran.us.r-project.org")
if(!require(grid)) install.packages("grid", repos = "http://cran.us.r-project.org")
if(!require(readr)) install.packages("readr", repos = "http://cran.us.r-project.org")
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(ggfortify)) install.packages("ggfortify", repos = "http://cran.us.r-project.org")
if(!require(glmnet)) install.packages("glmnet", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
if(!require(nnet)) install.packages("nnet", repos = "http://cran.us.r-project.org")
if(!require(funModeling)) install.packages("funModeling", repos = "http://cran.us.r-project.org")
if(!require(Momocs)) install.packages("Momocs", repos = "http://cran.us.r-project.org")
library(funModeling)
library(corrplot)

# The data file will be loaded from my github account
data <- read.csv("https://raw.githubusercontent.com/ashi2205/Final-Project/master/data.csv")
```

The dataset’s features describe characteristics of the cell nuclei on the image. The features information are specified below:

 - Attribute Information:

    1. ID number
    2. Diagnosis (M = malignant, B = benign)

 - Ten features were computed for each cell nucleus:

1. radius: mean of distances from center to points on the perimeter of each cell
2. texture: standard deviation of grey-scale values
3. perimeter
4. area: Number of pixels inside contour + ½ for pixels on perimeter
5. smoothness: local variation in radius lengths
6. compactness: perimeter^2 / area – 1.0 ; this dimensionless number is at a minimum with a circular disk and increases with the                 irregularity of the boundary, but this measure also increases for elongated cell nuclei, which is not                           indicative of malignancy
7. concavity: severity of concave portions of the contour
8. concave points: number of concave portions of the contour
9. symmetry
10. fractal dimension: “coastline approximation” - 1; a higher value corresponds to a less regular contour and thus to a higher probability of malignancy

The mean, standard error and “worst” or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 variables. From this diagnosis, 357 of the cases were classified as benign tumors and 212 were considered malignant tumors. 

The column 33 is invalid.

```{r}
data$diagnosis <- as.factor(data$diagnosis)
# the 33 column is invalid
data[,33] <- NULL
```

# Methods and Analysis

## Data Analysis

By observing our dataset, we found that it contains 569 observations with 32 variables.
```{r}
str(data)
```
```{r}
head(data)
```
```{r}
summary(data)
```
We have to check if the dataset has any missing value:
```{r, echo = FALSE, message = FALSE, warning = FALSE, eval = TRUE}
map(data, function(.x) sum(is.na(.x)))
```
It results that there aren't NA values.
By analysing the the dataset we discover that it is a bit unbalanced in its proportions:
```{r}
prop.table(table(data$diagnosis))
```
Also the plot of proportions confirms that the target variable is slightly unbalanced.
```{r}
options(repr.plot.width=4, repr.plot.height=4)
ggplot(data, aes(x=diagnosis))+geom_bar(fill="pink",alpha=0.5)+theme_bw()+labs(title="Distribution of Diagnosis")
```
The most variables of the dataset are normally distributed as show with the below plot:
```{r}
plot_num(data %>% select(-id), bins=10)
```
Now we have to check if there is any correlation between variables as machine learning algorithms assume that the predictor variables are independent from each others.
```{r}
correlationMatrix <- cor(data[,3:ncol(data)])
corrplot(correlationMatrix, order = "hclust", tl.cex = 1, addrect = 8)
```
As shown by this plot, many variables are highly correlated with each others. Many methods perform better if highly correlated attributes are removed. The Caret R package provides the findCorrelation which will analyze a correlation matrix of your data’s attributes report on attributes that can be removed. Because of much correlation some machine learning models could fail.
```{r}
# find attributes that are highly corrected (ideally >0.90)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.9)
# print indexes of highly correlated attributes
print(highlyCorrelated)
```
Selecting the right features in our data can mean the difference between mediocre performance with long training times and great performance with short training times.
```{r}
# Remove correlated variables
data2 <- data %>%select(-highlyCorrelated)
# number of columns after removing correlated variables
ncol(data2)
```
The new dataset has loss 10 variables.

## Modelling Approach

### Modelling

Principal Component Analysis (PCA).

To avoid redundancy and relevancy, we used the function ‘prcomp’ to calculate the Principal Component Analysis (PCA) and select the right components to avoid correlated variables that can be detrimental to our clustering analysis.
One of the common problems in analysis of complex data comes from a large number of variables, which requires a large amount of memory and computation power. This is where PCA comes in. It is a technique to reduce the dimension of the feature space by feature extraction.
PCA is used in exploratory data analysis and for making predictive models. It is commonly used for dimensionality reduction by projecting each data point onto only the first few principal components to obtain lower-dimensional data while preserving as much of the data's variation as possible.
```{r}
pca_res_data <- prcomp(data[,3:ncol(data)], center = TRUE, scale = TRUE)
plot(pca_res_data, type="l")
```
```{r}
summary(pca_res_data)
```
As we can observe from the above table, the two first components explains the 0.6324 of the variance. We need 10 principal components to explain more than 0.95 of the variance and 17 to explain more than 0.99.
```{r}
pca_res_data2 <- prcomp(data2[,3:ncol(data2)], center = TRUE, scale = TRUE)
plot(pca_res_data2, type="l")
```
```{r}
summary(pca_res_data2)
```
The above table shows that 95% of the variance is explained with 8 PC's in the transformed dataset data2.
```{r}
pca_df <- as.data.frame(pca_res_data2$x)
ggplot(pca_df, aes(x=PC1, y=PC2, col=data$diagnosis)) + geom_point(alpha=0.5)
```
The data of the first 2 components can be easly separated into two classes. This is caused by the fact that the variance explained by these components is not large. The data can be easily separated.

```{r}
g_pc1 <- ggplot(pca_df, aes(x=PC1, fill=data$diagnosis)) + geom_density(alpha=0.25)  
g_pc2 <- ggplot(pca_df, aes(x=PC2, fill=data$diagnosis)) + geom_density(alpha=0.25)  
grid.arrange(g_pc1, g_pc2, ncol=2)
```

Linear Discriminant Analysis (LDA)

Linear discriminant analysis (LDA) is a generalization of Fisher's linear discriminant, a method used in statistics and other fields, to find a linear combination of features that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a linear classifier, or, more commonly, for dimensionality reduction before later classification. It is important to know that LDA assumes a normal distribution for each class, a class-specific mean, and a common variance.

```{r}
lda_res_data <- MASS::lda(diagnosis~., data = data, center = TRUE, scale = TRUE) 
lda_res_data

#Data frame of the LDA for visualization purposes
lda_df_predict <- predict(lda_res_data, data)$x %>% as.data.frame() %>% cbind(diagnosis=data$diagnosis)
```

```{r}
ggplot(lda_df_predict, aes(x=LD1, fill=diagnosis)) + geom_density(alpha=0.5)
```

### Model creation

We are going to get a training and a testing set to use when building some models. We split the modified dataset into Train (80%) and Test (20%), in order to predict is whether a cancer cell is Benign or Malignant, by building machine learning classification models.

```{r}
set.seed(1815)
data3 <- cbind (diagnosis=data$diagnosis, data2)
data_sampling_index <- createDataPartition(data$diagnosis, times=1, p=0.8, list = FALSE)
train_data <- data3[data_sampling_index, ]
test_data <- data3[-data_sampling_index, ]


fitControl <- trainControl(method="cv",    #Control the computational nuances of thetrainfunction
                           number = 15,    #Either the number of folds or number of resampling iterations
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary)
```


### Logistic Regression Model 

Logistic regression is the appropriate regression analysis to conduct when the dependent variable is dichotomous (binary).  Like all regression analyses, the logistic regression is a predictive analysis.  Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.
Logistic Regression is widely used for binary classification like (0,1). The binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features).

```{r}
model_logreg<- train(diagnosis ~., data = train_data, method = "glm",
                     metric = "ROC",
                     
                     preProcess = c("scale", "center"),  # in order to normalize the data
                     trControl= fitControl)
prediction_logreg<- predict(model_logreg, test_data)

# Check results
confusionmatrix_logreg <- confusionMatrix(prediction_logreg, test_data$diagnosis, positive = "M")
confusionmatrix_logreg

```
The most important variables that permit the best prediction and contribute the most to the model are the following:

```{r}
plot(varImp(model_logreg), top=10, main="Top variables - Log Regr")
```


### Random Forest Model

Random Forest is a supervised learning algorithm and it is flexible, easy to use machine learning algorithm that produces, even without hyper-parameter tuning, a great result most of the time. It is also one of the most used algorithms, because of it’s simplicity and the fact that it can be used for both classification and regression tasks.
Random forest builds multiple decision trees and merges them together to get a more accurate and stable prediction.

```{r}
model_randomforest <- train(diagnosis~.,
                            train_data,
                            method="rf",  #also recommended ranger, because it is a lot faster than original randomForest (rf)
                            metric="ROC",
                            #tuneLength=10,
                            #tuneGrid = expand.grid(mtry = c(2, 3, 6)),
                            preProcess = c('center', 'scale'),
                            trControl=fitControl)

prediction_randomforest <- predict(model_randomforest, test_data)

#Check results
confusionmatrix_randomforest <- confusionMatrix(prediction_randomforest, test_data$diagnosis, positive = "M")
confusionmatrix_randomforest
```

```{r}
plot(varImp(model_randomforest), top=10, main="Top variables- Random Forest")
```


### K Nearest Neighbor (KNN) Model

KNN (K-Nearest Neighbors) is one of many (supervised learning) algorithms used in data mining and machine learning, it’s a classifier algorithm where the learning is based “how similar” is a data from other. K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions).

```{r}
model_knn <- train(diagnosis~.,
                   train_data,
                   method="knn",
                   metric="ROC",
                   preProcess = c('center', 'scale'),
                   tuneLength=10, #The tuneLength parameter tells the algorithm to try different default values for the main parameter
                   #In this case we used 10 default values
                   trControl=fitControl)

prediction_knn <- predict(model_knn, test_data)
confusionmatrix_knn <- confusionMatrix(prediction_knn, test_data$diagnosis, positive = "M")
confusionmatrix_knn
```

The most important variables that permit the best prediction and contribute the most to the model are the following:

```{r}
plot(varImp(model_knn), top=10, main="Top variables - KNN")
```


### Neural Network with PCA Model

Artificial Neural Networks (NN) are a type of mathematical algorithms originating in the simulation of networks of biological neurons.
An artificial Neural Network consists of nodes (called neurons) and edges (called synapses). Input data is transmitted through the weighted synapses to the neurons where calculations are processed and then either sent to further neurons or are the output.

Neural Networks take in the weights of connections between neurons. When all weights are trained, the neural network can be utilized to predict the class or a quantity, if there should arise an occurrence of regression of a new input data point. With Neural networks, extremely complex models can be trained and they can be utilized as a kind of black box, without playing out an unpredictable complex feature engineering before training the model. Joined with the “deep approach” even more unpredictable models can be picked up to realize new possibilities. 
```{r}
model_nnet_pca <- train(diagnosis~.,
                        train_data,
                        method="nnet",
                        metric="ROC",
                        preProcess=c('center', 'scale', 'pca'),
                        tuneLength=10,
                        trace=FALSE,
                        trControl=fitControl)

prediction_nnet_pca <- predict(model_nnet_pca, test_data)
confusionmatrix_nnet_pca <- confusionMatrix(prediction_nnet_pca, test_data$diagnosis, positive = "M")
confusionmatrix_nnet_pca


```
The most important variables that permit the best prediction and contribute the most to the model are the following:

```{r}
plot(varImp(model_nnet_pca), top=8, main="Top variables - NNET PCA")
```


### Neural Network with LDA Model

Topic models are a class of probabilistic models for text analysis, widely used in many research areas that use textual data as their research material. The most widely used topic model, Latent Dirichlet Analysis (LDA)is a hierarchical Bayesian model that is typically implemented using MCMC or variational inference methods.

We are going to create a training and test set of LDA data created in previous chapters:

```{r}
train_data_lda <- lda_df_predict[data_sampling_index, ]
test_data_lda <- lda_df_predict[-data_sampling_index, ]
```

```{r}
model_nnet_lda <- train(diagnosis~.,
                        train_data_lda,
                        method="nnet",
                        metric="ROC",
                        preProcess=c('center', 'scale'),
                        tuneLength=10,
                        trace=FALSE,
                        trControl=fitControl)

prediction_nnet_lda <- predict(model_nnet_lda, test_data_lda)
confusionmatrix_nnet_lda <- confusionMatrix(prediction_nnet_lda, test_data_lda$diagnosis, positive = "M")
confusionmatrix_nnet_lda
```
# Results

We can now compare and evaluate the results obtained with the above calculations.
```{r}
models_list <- list(Logistic_regr=model_logreg,
                    Random_Forest=model_randomforest,
                    KNN=model_knn,
                    Neural_PCA=model_nnet_pca,
                    Neural_LDA=model_nnet_lda)                                     
models_results <- resamples(models_list)

summary(models_results)
```

The Neural Network LDA model achieves a great auc (Area Under the ROC Curve) with some variability. The ROC (Receiver Operating characteristic Curve is a graph showing the performance of a classification model at all classification thresholds) metric measure the auc of the roc curve of each model. This metric is independent of any threshold. Let’s remember how these models result with the testing dataset. Prediction classes are obtained by default with a threshold of 0.5 which could not be the best with an unbalanced dataset like this.

```{r}
confusionmatrix_list <- list(
  Logistic_regr=confusionmatrix_logreg,
  Random_Forest=confusionmatrix_randomforest,
  KNN=confusionmatrix_knn,
  Neural_PCA=confusionmatrix_nnet_pca,
  Neural_LDA=confusionmatrix_nnet_lda)   
confusionmatrix_list_results <- sapply(confusionmatrix_list, function(x) x$byClass)
confusionmatrix_list_results %>% knitr::kable()
```


# Discussion

We will now describe the metrics that we will compare in this section.

Accuracy is our starting point. It is the number of correct predictions made divided by the total number of predictions made, multiplied by 100 to turn it into a percentage.

Precision is the number of True Positives divided by the number of True Positives and False Positives. It is also called the Positive Predictive Value (PPV). A low precision can also indicate a large number of False Positives.

Recall (Sensitivity) is the number of True Positives divided by the number of True Positives and the number of False Negatives. It is also called Sensitivity or the True Positive Rate. Recall can be thought of as a measure of a classifiers completeness. A low recall indicates many False Negatives.

The F1 Score is the 2 x ((precision x recall) / (precision + recall)). It is also called the F Score or the F Measure. Put another way, the F1 score conveys the balance between the precision and the recall.

The best results for sensitivity (detection of breast cancer malign cases) is Neural Network with LDA model which also has a great F1 score.


```{r}
confusionmatrix_results_max <- apply(confusionmatrix_list_results, 1, which.is.max)

output_report <- data.frame(metric=names(confusionmatrix_results_max), 
                            best_model=colnames(confusionmatrix_list_results)[confusionmatrix_results_max],
                            value=mapply(function(x,y) {confusionmatrix_list_results[x,y]}, 
                                         names(confusionmatrix_results_max), 
                                         confusionmatrix_results_max))
rownames(output_report) <- NULL
output_report
```

# Conclusion

This report treats the Wisconsin Madison Breast Cancer diagnosis problem as a pattern classification problem. In this report we investigated several machine learning model and we selected the optimal model by selecting a high accuracy level combined with a low rate of false-negatives and low rate of false-positives.

The Neural Network with LDA model had the optimal results for F1 (0.9761905), Sensitivity (0.9761905) and Balanced Accuracy (0.9810530)


